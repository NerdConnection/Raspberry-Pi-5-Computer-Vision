# 용도 별 분류

### 1. Convolutional Neural Networks (CNNs)
목적: 이미지 분류, 객체 인식, 이미지 분할 등 <br/>
예시 모델: AlexNet, VGGNet, ResNet, Inception, MobileNet <br/>
설명: CNN은 이미지의 시각적 내용을 이해하는 데 강력하며, 다양한 컴퓨터 비전 작업에 널리 사용

### 2. Object Detection Models
목적: 이미지 내 객체의 위치 식별 및 분류 <br/>
예시 모델: YOLO (You Only Look Once), SSD (Single Shot MultiBox Detector), Faster R-CNN <br/>
설명: 이 모델들은 실시간 객체 검출에 유용하며, 다양한 객체를 빠르고 정확하게 식별

### 3. Semantic Segmentation Models
목적: 이미지 내의 각 픽셀이 어떤 객체에 속하는지 분류 <br/>
예시 모델: U-Net, SegNet, DeepLab <br/>
설명: 의료 영상, 자율 주행 자동차 등 특정 분야에서 매우 중요

### 4. Pose Estimation Models
목적: 이미지나 비디오에서 인간의 자세를 추정 <br/>
예시 모델: OpenPose, AlphaPose <br/>
설명: 스포츠 분석, 인터랙티브 게임, 건강 관리 등

### 5. Face Recognition Models
목적: 얼굴 인식 및 검증 <br/>
예시 모델: FaceNet, DeepFace, Dlib's face recognition <br/>
설명: 보안 시스템, 개인화된 사용자 경험 제공 등

<hr/>

# RasPi, Docker, CSI 카메라를 고려한 모델

#### 1. MobileNet
특징: 가벼우면서도 높은 정확도. 모바일 및 임베디드 기기에서의 실행에 최적화. <br/>
적합한 작업: 이미지 분류, 객체 검출

#### 2. YOLO (You Only Look Once)
특징: 빠른 추론 속도, 실시간 객체 검출에 적합. <br/>
적합한 작업: 실시간 객체 검출

#### 3. SSD (Single Shot MultiBox Detector)
특징: YOLO와 유사. 다양한 객체 크기에 대해 좋은 성능. <br/>
적합한 작업: 객체 검출

#### 4. Tiny YOLO
특징: YOLO의 경량 버전으로, 매우 제한된 컴퓨팅 리소스에서도 사용 가능. <br/>
적합한 작업: 실시간 객체 검출

#### 5. OpenPose
특징: 사람의 자세를 실시간으로 추정할 수 있는 고급 모델. 상대적으로 더 많은 컴퓨팅 자원을 요구. <br/>
적합한 작업: 포즈 추정

#### 6. EfficientDet
특징: 효율성과 정확도 사이의 높은 균형. 리소스 제한 환경에서도 높은 성능 유지. <br/>
적합한 작업: 실시간 객체 검출, 이미지 내 다수의 객체 인식 및 분류

#### 7. SqueezeNet
특징: 작은 모델 크기에 초점을 맞춘 CNN 아키텍처. 모바일 또는 임베디드 시스템에서의 실행을 고려하여 설계. AlexNet 수준의 정확도를 유지하면서 모델 크기를 대폭 줄임. <br/>
적합한 작업: 이미지 분류, 기본적인 컴퓨터 비전 작업

#### 8. Mask R-CNN
특징: Mask R-CNN은 객체 검출과 함께 객체의 정확한 영역을 분할하는 것이 가능한 모델. 이미지 내 객체의 정밀한 위치와 형태를 파악하는 데 사용. <br/>
적합한 작업: 객체 검출 및 세그멘테이션, 고정밀 객체 인식 및 추적

#### 9. Siamese Networks
특징: 두 입력 이미지 사이의 유사도를 측정하는 데 사용. 이를 통해 같은 객체인지 다른 객체인지를 판별.
적합한 작업: 얼굴 인식, 이미지 매칭, 감시 시스템

<hr/>

# RasPi에서 Model을 실행하기 위해

1. 제한된 리소스를 가진 환경이기 때문에 MobileNet이나 Tiny YOLO같은 가벼운 버전을 사용하는 것이 좋음
2. 런타임 최적화를 위해 TensorFlow Lite나 PyTorch Mobile같은 경량화 머신러닝 라이브러리를 사용하여 모델 시랳ㅇ
3. RasPi의 멀티코어 CPU를 활용하여 모델 추론 과정을 병렬로 실행하여 전체 처리 시간 단축
4. OpenCV의 DNN모듈을 활용하여 GPU 가속 활성화 (RasPi에서 가능할지 모르겠음)

#### CSI 카메라로 실시간 비디오 처리
- OpenCV를 활용하여 비디오 스트림 캡처
- AI 모델이 처리할 수 있도록 각 비디오 프레임과 크기 조정이 필요함

<hr/>

## 발표자료 예시
#### 1. 프로젝트 요구사항 정의 및 계획 수립
목표 설정: 프로젝트의 최종 목표를 명확히 정의합니다. <br/>
요구사항 분석: 사용될 AI 모델의 종류, 웹 UI의 기능, 사용자 요구사항 등을 구체화합니다. <br/>
기술 스택 결정: Raspberry Pi 5에서 실행될 AI 프레임워크, 웹 서버, 웹소켓 라이브러리 등 필요한 기술을 선정합니다.

#### 2. 하드웨어 및 소프트웨어 환경 설정
Raspberry Pi 설정: Raspberry Pi 5와 CSI 카메라 연결 및 설정을 완료합니다. <br/>
도커 환경 준비: AI 프레임워크와 웹 서버가 실행될 도커 컨테이너를 생성합니다. 필요에 따라 도커 이미지를 수정하거나 커스텀 이미지를 만듭니다.

#### 3. AI 모델 및 서버 개발
AI 모델 통합: 다양한 AI 모델을 선택적으로 실행할 수 있도록 도커 환경 내에 통합합니다. 모델의 성능과 호환성을 테스트합니다. <br/>
웹 UI 개발: 사용자가 AI 모델을 쉽게 선택하고 실행 결과를 볼 수 있도록 웹 기반 UI를 개발합니다. 반응형 디자인을 고려하여 모바일과 데스크톱에서 모두 사용 가능하도록 합니다. <br/>
웹소켓 서버 개발: AI 모델 선택 및 실행 결과 전송을 위한 웹소켓 서버를 구축합니다. JSON 등의 프로토콜을 사용하여 클라이언트와 서버 간의 통신을 정의합니다.

#### 4. 테스트 및 최적화
기능 테스트: 개발된 웹 UI와 웹소켓 서버가 예상대로 작동하는지 테스트합니다. 사용자 입장에서의 경험도 평가합니다. <br/>
성능 최적화: AI 모델의 실행 시간, 웹 서버의 응답 속도 등을 분석하고 최적화합니다. 필요시 하드웨어 리소스 할당을 조정합니다.

#### 5. 배포 및 모니터링
배포: 모든 개발이 완료되면 시스템을 실제 환경에 배포합니다. 사용자로부터의 피드백을 수집합니다. <br/>
모니터링 및 유지보수: 시스템의 성능을 지속적으로 모니터링하고, 발생할 수 있는 문제에 대해 즉각적으로 대응합니다. <br/>
